# Windows Filebeat → Kafka → Logstash → Elasticsearch 전체 파이프라인 가이드

## 1. 전체 아키텍처

```
[Tomcat Logs] → [Filebeat] → [Kafka] → [Logstash] → [Elasticsearch] → [Kibana]
     ↓              ↓           ↓           ↓              ↓
   파일들         수집/전송    버퍼링      처리/변환      저장/인덱싱
```

### 1.1 수집 대상 Tomcat 로그 파일들

```
C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs\
├── catalina.yyyy-mm-dd.log          # Tomcat 서버 로그
├── localhost.yyyy-mm-dd.log         # 호스트 로그
├── localhost_access_log.yyyy-mm-dd.txt  # 액세스 로그
├── host-manager.yyyy-mm-dd.log      # 호스트 매니저 로그
├── manager.yyyy-mm-dd.log            # 매니저 앱 로그
├── tomcat9-stderr.yyyy-mm-dd.log    # 표준 에러 출력
└── tomcat9-stdout.yyyy-mm-dd.log    # 표준 출력
```

### 1.2 Elasticsearch 인덱스 구조

```
tomcat-catalina-2024.12.08     # 카탈리나 로그
tomcat-access-2024.12.08       # 액세스 로그
tomcat-stderr-2024.12.08       # 에러 출력
tomcat-stdout-2024.12.08       # 표준 출력
tomcat-manager-2024.12.08      # 매니저 로그
tomcat-localhost-2024.12.08    # 로컬호스트 로그
```

## 2. Filebeat 설치 및 설정

### 2.1 Filebeat 설치

```powershell
# PowerShell 관리자 권한
$version = "8.11.1"
$url = "https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-$version-windows-x86_64.zip"
$output = "$env:TEMP\filebeat.zip"

# 다운로드 및 설치
Invoke-WebRequest -Uri $url -OutFile $output
Expand-Archive -Path $output -DestinationPath "C:\Program Files\" -Force
Rename-Item "C:\Program Files\filebeat-$version-windows-x86_64" "C:\Program Files\Filebeat" -Force

cd "C:\Program Files\Filebeat"
.\install-service-filebeat.ps1
```

### 2.2 filebeat.yml 전체 설정

```yaml
# C:\Program Files\Filebeat\filebeat.yml

# ======================== Filebeat Inputs ========================
filebeat.inputs:

# ------------ Catalina 메인 로그 ------------
- type: log
  enabled: true
  paths:
    - 'C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs\catalina.*.log'
  
  # 파일 인코딩
  encoding: utf-8
  
  # 멀티라인 처리 (스택트레이스)
  multiline.pattern: '^\d{2}-[A-Za-z]{3}-\d{4}\s+\d{2}:\d{2}:\d{2}'
  multiline.negate: true
  multiline.match: after
  multiline.max_lines: 1000
  
  # 파일 관리
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  clean_removed: true
  scan_frequency: 10s
  ignore_older: 72h
  
  # 메타데이터
  fields:
    log_type: catalina
    service: tomcat
    environment: production
    server_name: ${COMPUTERNAME}
  fields_under_root: false
  
  tags: ["tomcat", "catalina", "windows"]

# ------------ STDERR 로그 (에러 출력) ------------
- type: log
  enabled: true
  paths:
    - 'C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs\tomcat9-stderr.*.log'
  
  encoding: utf-8
  
  # Java 예외 처리
  multiline.pattern: '^\d{4}-\d{2}-\d{2}|^[A-Z][a-z]{2}\s+\d{2},\s+\d{4}|^\s+at\s+|^Caused by:|^\s+\.\.\.'
  multiline.negate: false
  multiline.match: after
  multiline.max_lines: 500
  
  fields:
    log_type: stderr
    service: tomcat
    environment: production
  
  tags: ["tomcat", "stderr", "error", "windows"]

# ------------ STDOUT 로그 (표준 출력) ------------
- type: log
  enabled: true
  paths:
    - 'C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs\tomcat9-stdout.*.log'
  
  encoding: utf-8
  
  multiline.pattern: '^\d{4}-\d{2}-\d{2}|^[A-Z][a-z]{2}\s+\d{2},\s+\d{4}'
  multiline.negate: true
  multiline.match: after
  
  fields:
    log_type: stdout
    service: tomcat
    environment: production
  
  tags: ["tomcat", "stdout", "windows"]

# ------------ Access 로그 ------------
- type: log
  enabled: true
  paths:
    - 'C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs\localhost_access_log.*.txt'
  
  encoding: utf-8
  
  # Access 로그는 단일 라인
  fields:
    log_type: access
    service: tomcat
    environment: production
  
  tags: ["tomcat", "access", "http", "windows"]

# ------------ Localhost 로그 ------------
- type: log
  enabled: true
  paths:
    - 'C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs\localhost.*.log'
  
  encoding: utf-8
  
  multiline.pattern: '^\d{2}-[A-Za-z]{3}-\d{4}'
  multiline.negate: true
  multiline.match: after
  
  fields:
    log_type: localhost
    service: tomcat
    environment: production
  
  tags: ["tomcat", "localhost", "windows"]

# ------------ Manager 로그 ------------
- type: log
  enabled: true
  paths:
    - 'C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs\manager.*.log'
  
  encoding: utf-8
  
  multiline.type: pattern
  multiline.pattern: '^\d{2}-[A-Za-z]{3}-\d{4}'
  multiline.negate: true
  multiline.match: after
  
  fields:
    log_type: manager
    service: tomcat
    environment: production
  
  tags: ["tomcat", "manager", "windows"]

# ------------ Host Manager 로그 ------------
- type: log
  enabled: true
  paths:
    - 'C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs\host-manager.*.log'
  
  encoding: utf-8
  
  multiline.type: pattern
  multiline.pattern: '^\d{2}-[A-Za-z]{3}-\d{4}'
  multiline.negate: true
  multiline.match: after
  
  fields:
    log_type: host-manager
    service: tomcat
    environment: production
  
  tags: ["tomcat", "host-manager", "windows"]

# ======================== Processors ========================
processors:
  # 호스트 메타데이터 추가
  - add_host_metadata:
      when.not.contains.tags: forwarded
  
  # 타임스탬프 추가
  - timestamp:
      field: '@timestamp'
      layouts:
        - '2006-01-02T15:04:05Z'
        - '2006-01-02T15:04:05.000Z'
  
  # 로그 레벨 추출 (JavaScript 대신 조건부 필드 사용)
  # ERROR 레벨 감지
  - add_fields:
      when.or:
        - contains.message: "ERROR"
        - contains.message: "SEVERE"
        - contains.message: "FATAL"
      target: ''
      fields:
        log.level: "ERROR"
        severity: "high"
        error.detected: true
  
  # WARN 레벨 감지
  - add_fields:
      when.or:
        - contains.message: "WARN"
        - contains.message: "WARNING"
      target: ''
      fields:
        log.level: "WARN"
        severity: "medium"
  
  # INFO 레벨 감지
  - add_fields:
      when.contains.message: "INFO"
      target: ''
      fields:
        log.level: "INFO"
        severity: "low"
  
  # DEBUG 레벨 감지
  - add_fields:
      when.or:
        - contains.message: "DEBUG"
        - contains.message: "FINE"
        - contains.message: "TRACE"
      target: ''
      fields:
        log.level: "DEBUG"
        severity: "low"
  
  # Exception 감지
  - add_fields:
      when.or:
        - contains.message: "Exception"
        - contains.message: "at "
        - contains.message: "Caused by:"
      target: ''
      fields:
        error.type: "exception"
        error.detected: true

# ======================== Kafka Output ========================
output.kafka:
  # Kafka 브로커
  hosts: ["192.168.1.101:9092", "192.168.1.102:9092", "192.168.1.103:9092"]
  
  # 동적 토픽 라우팅 (log_type 기반)
  topic: 'tomcat-%{[fields.log_type]}'
  
  # 파티션 설정
  partition.round_robin:
    reachable_only: false
  
  # 압축
  compression: gzip
  compression_level: 4
  
  # 신뢰성
  required_acks: 1
  max_retries: 3
  
  # 메타데이터
  client_id: "filebeat-tomcat-windows"

# ======================== Logging ========================
logging.level: info
logging.to_files: true
logging.files:
  path: C:\ProgramData\filebeat\logs
  name: filebeat
  keepfiles: 7
  permissions: 0640

# ======================== Monitoring ========================
monitoring.enabled: true
http.enabled: true
http.host: localhost
http.port: 5066
```

## 3. Kafka 토픽 생성

### 3.1 토픽 생성 스크립트

```bash
#!/bin/bash
# create-tomcat-topics.sh

KAFKA_HOME="/opt/kafka"
BOOTSTRAP_SERVER="localhost:9092"

# 로그 타입별 토픽 생성
topics=("tomcat-catalina" "tomcat-stderr" "tomcat-stdout" "tomcat-access" 
        "tomcat-localhost" "tomcat-manager" "tomcat-host-manager")

for topic in "${topics[@]}"; do
    echo "Creating topic: $topic"
    $KAFKA_HOME/bin/kafka-topics.sh --create \
        --bootstrap-server $BOOTSTRAP_SERVER \
        --topic $topic \
        --partitions 6 \
        --replication-factor 3 \
        --config retention.ms=604800000 \
        --config compression.type=lz4 \
        --config segment.ms=3600000
done

# 토픽 확인
$KAFKA_HOME/bin/kafka-topics.sh --list --bootstrap-server $BOOTSTRAP_SERVER | grep tomcat
```

## 4. Logstash 파이프라인 설정

### 4.1 메인 파이프라인 (kafka-to-elasticsearch.conf)

```ruby
# /etc/logstash/conf.d/kafka-to-elasticsearch.conf

input {
  # Catalina 로그
  kafka {
    bootstrap_servers => "192.168.1.101:9092,192.168.1.102:9092,192.168.1.103:9092"
    topics => ["tomcat-catalina"]
    group_id => "logstash-tomcat-catalina"
    consumer_threads => 2
    codec => json
    decorate_events => true
    type => "catalina"
  }
  
  # STDERR 로그
  kafka {
    bootstrap_servers => "192.168.1.101:9092,192.168.1.102:9092,192.168.1.103:9092"
    topics => ["tomcat-stderr"]
    group_id => "logstash-tomcat-stderr"
    consumer_threads => 2
    codec => json
    type => "stderr"
  }
  
  # STDOUT 로그
  kafka {
    bootstrap_servers => "192.168.1.101:9092,192.168.1.102:9092,192.168.1.103:9092"
    topics => ["tomcat-stdout"]
    group_id => "logstash-tomcat-stdout"
    consumer_threads => 1
    codec => json
    type => "stdout"
  }
  
  # Access 로그
  kafka {
    bootstrap_servers => "192.168.1.101:9092,192.168.1.102:9092,192.168.1.103:9092"
    topics => ["tomcat-access"]
    group_id => "logstash-tomcat-access"
    consumer_threads => 2
    codec => json
    type => "access"
  }
  
  # 기타 로그들
  kafka {
    bootstrap_servers => "192.168.1.101:9092,192.168.1.102:9092,192.168.1.103:9092"
    topics => ["tomcat-localhost", "tomcat-manager", "tomcat-host-manager"]
    group_id => "logstash-tomcat-others"
    consumer_threads => 1
    codec => json
    type => "others"
  }
}

filter {
  # ============ 공통 처리 ============
  # Filebeat 메타데이터 처리
  if [agent][type] == "filebeat" {
    mutate {
      add_field => {
        "[@metadata][beat_version]" => "%{[agent][version]}"
        "[@metadata][beat_hostname]" => "%{[agent][hostname]}"
      }
    }
  }
  
  # 타임스탬프 파싱
  date {
    match => [ "@timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  # ============ Catalina 로그 처리 ============
  if [type] == "catalina" or [fields][log_type] == "catalina" {
    grok {
      match => {
        "message" => [
          # 표준 Catalina 로그 패턴
          "%{MONTHDAY:day}-%{MONTH:month}-%{YEAR:year} %{TIME:time} %{LOGLEVEL:level} \[%{DATA:thread}\] %{JAVACLASS:class}\.%{WORD:method} %{GREEDYDATA:log_message}",
          # 대체 패턴
          "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:thread}\] %{GREEDYDATA:log_message}",
          # 기본 패턴
          "%{GREEDYDATA:log_message}"
        ]
      }
    }
    
    # 날짜 조합
    if [day] and [month] and [year] and [time] {
      mutate {
        add_field => { "log_timestamp" => "%{day}-%{month}-%{year} %{time}" }
      }
      date {
        match => [ "log_timestamp", "dd-MMM-yyyy HH:mm:ss.SSS" ]
        target => "log_time"
      }
      mutate {
        remove_field => [ "day", "month", "year", "time", "log_timestamp" ]
      }
    }
    
    mutate {
      add_field => { "[@metadata][index_name]" => "tomcat-catalina" }
    }
  }
  
  # ============ STDERR 로그 처리 ============
  else if [type] == "stderr" or [fields][log_type] == "stderr" {
    # Java Exception 파싱
    if [message] =~ /Exception|Error/ {
      grok {
        match => {
          "message" => [
            "%{JAVACLASS:exception_class}: %{GREEDYDATA:exception_message}",
            "Caused by: %{JAVACLASS:caused_by_class}: %{GREEDYDATA:caused_by_message}"
          ]
        }
        tag_on_failure => []
      }
      
      mutate {
        add_field => { "error_type" => "exception" }
        add_tag => [ "error", "exception" ]
      }
    }
    
    # 스택트레이스 감지
    if [message] =~ /^\s+at\s+/ {
      mutate {
        add_tag => [ "stacktrace" ]
      }
    }
    
    mutate {
      add_field => { "[@metadata][index_name]" => "tomcat-stderr" }
    }
  }
  
  # ============ STDOUT 로그 처리 ============
  else if [type] == "stdout" or [fields][log_type] == "stdout" {
    # 애플리케이션 로그 패턴
    grok {
      match => {
        "message" => [
          "%{TIMESTAMP_ISO8601:app_timestamp} \[%{LOGLEVEL:level}\] %{GREEDYDATA:log_message}",
          "%{GREEDYDATA:log_message}"
        ]
      }
      tag_on_failure => []
    }
    
    mutate {
      add_field => { "[@metadata][index_name]" => "tomcat-stdout" }
    }
  }
  
  # ============ Access 로그 처리 ============
  else if [type] == "access" or [fields][log_type] == "access" {
    grok {
      match => {
        "message" => '%{IPORHOST:client_ip} - %{DATA:user_auth} \[%{HTTPDATE:access_time}\] "%{WORD:http_method} %{DATA:request_uri} HTTP/%{NUMBER:http_version}" %{NUMBER:response_code:int} %{NUMBER:response_size:int} "%{DATA:referrer}" "%{DATA:user_agent}" %{NUMBER:response_time:float}'
      }
      tag_on_failure => ["_grokparsefailure_access"]
    }
    
    # 접근 시간 파싱
    if [access_time] {
      date {
        match => [ "access_time", "dd/MMM/yyyy:HH:mm:ss Z" ]
        target => "access_timestamp"
      }
    }
    
    # GeoIP (클라이언트 IP)
    if [client_ip] {
      geoip {
        source => "client_ip"
        target => "geoip"
      }
    }
    
    # 응답 코드 분류
    if [response_code] {
      if [response_code] >= 200 and [response_code] < 300 {
        mutate { add_field => { "response_status" => "success" } }
      } else if [response_code] >= 300 and [response_code] < 400 {
        mutate { add_field => { "response_status" => "redirect" } }
      } else if [response_code] >= 400 and [response_code] < 500 {
        mutate { add_field => { "response_status" => "client_error" } }
        mutate { add_tag => [ "client_error" ] }
      } else if [response_code] >= 500 {
        mutate { add_field => { "response_status" => "server_error" } }
        mutate { add_tag => [ "server_error", "alert" ] }
      }
    }
    
    # User Agent 파싱
    if [user_agent] {
      useragent {
        source => "user_agent"
        target => "ua"
      }
    }
    
    mutate {
      add_field => { "[@metadata][index_name]" => "tomcat-access" }
    }
  }
  
  # ============ 기타 로그 처리 ============
  else {
    if [fields][log_type] == "localhost" {
      mutate {
        add_field => { "[@metadata][index_name]" => "tomcat-localhost" }
      }
    } else if [fields][log_type] == "manager" {
      mutate {
        add_field => { "[@metadata][index_name]" => "tomcat-manager" }
      }
    } else if [fields][log_type] == "host-manager" {
      mutate {
        add_field => { "[@metadata][index_name]" => "tomcat-host-manager" }
      }
    } else {
      mutate {
        add_field => { "[@metadata][index_name]" => "tomcat-others" }
      }
    }
  }
  
  # ============ 최종 처리 ============
  # 로그 레벨 정규화
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
    
    # 심각도 점수 추가
    if [level] == "ERROR" or [level] == "SEVERE" or [level] == "FATAL" {
      mutate { add_field => { "severity_score" => 5 } }
    } else if [level] == "WARN" or [level] == "WARNING" {
      mutate { add_field => { "severity_score" => 3 } }
    } else if [level] == "INFO" {
      mutate { add_field => { "severity_score" => 2 } }
    } else if [level] == "DEBUG" or [level] == "TRACE" {
      mutate { add_field => { "severity_score" => 1 } }
    }
  }
  
  # 필드 정리
  mutate {
    remove_field => [ "beat", "prospector", "offset", "source" ]
  }
}

output {
  # ============ Elasticsearch 출력 ============
  elasticsearch {
    hosts => ["192.168.1.104:9200", "192.168.1.105:9200", "192.168.1.106:9200"]
    
    # 동적 인덱스 이름 (일별)
    index => "%{[@metadata][index_name]}-%{+YYYY.MM.dd}"
    
    # 문서 ID (중복 방지)
    # document_id => "%{[@metadata][fingerprint]}"
    
    # 템플릿 관리
    manage_template => true
    template_name => "tomcat-logs"
    template => "/etc/logstash/templates/tomcat-template.json"
    template_overwrite => false
    
    # 성능 설정
    flush_size => 500
    idle_flush_time => 5
    
    # ILM 설정
    ilm_enabled => true
    ilm_rollover_alias => "%{[@metadata][index_name]}"
    ilm_pattern => "{now/d}-000001"
    ilm_policy => "tomcat-logs-policy"
  }
  
  # ============ 에러 로그 알림 (선택사항) ============
  if "alert" in [tags] or [severity_score] >= 5 {
    # 이메일 알림
    email {
      to => "admin@company.com"
      subject => "Tomcat Error Alert: %{[fields][server_name]}"
      body => "Error detected in %{[@metadata][index_name]}\n\nLevel: %{[level]}\nMessage: %{[message]}\nHost: %{[host][name]}"
      from => "logstash@company.com"
    }
  }
  
  # ============ 디버깅 (개발 환경) ============
  # stdout {
  #   codec => rubydebug
  # }
}
```

## 5. Elasticsearch 템플릿 및 ILM 정책

### 5.1 인덱스 템플릿 (tomcat-template.json)

```json
{
  "index_patterns": ["tomcat-*"],
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "index.codec": "best_compression",
    "index.refresh_interval": "5s",
    "index.translog.durability": "async",
    "index.translog.sync_interval": "5s",
    "index.query.default_field": "message"
  },
  "mappings": {
    "properties": {
      "@timestamp": {
        "type": "date"
      },
      "message": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 2048
          }
        }
      },
      "level": {
        "type": "keyword"
      },
      "severity_score": {
        "type": "integer"
      },
      "fields": {
        "properties": {
          "log_type": {
            "type": "keyword"
          },
          "service": {
            "type": "keyword"
          },
          "environment": {
            "type": "keyword"
          },
          "server_name": {
            "type": "keyword"
          }
        }
      },
      "host": {
        "properties": {
          "name": {
            "type": "keyword"
          },
          "hostname": {
            "type": "keyword"
          },
          "ip": {
            "type": "ip"
          },
          "os": {
            "properties": {
              "name": {
                "type": "keyword"
              },
              "version": {
                "type": "keyword"
              }
            }
          }
        }
      },
      "error": {
        "properties": {
          "detected": {
            "type": "boolean"
          },
          "type": {
            "type": "keyword"
          }
        }
      },
      "exception_class": {
        "type": "keyword"
      },
      "exception_message": {
        "type": "text"
      },
      "client_ip": {
        "type": "ip"
      },
      "response_code": {
        "type": "integer"
      },
      "response_size": {
        "type": "long"
      },
      "response_time": {
        "type": "float"
      },
      "response_status": {
        "type": "keyword"
      },
      "http_method": {
        "type": "keyword"
      },
      "request_uri": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      },
      "user_agent": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      },
      "geoip": {
        "properties": {
          "location": {
            "type": "geo_point"
          },
          "country_name": {
            "type": "keyword"
          },
          "city_name": {
            "type": "keyword"
          }
        }
      },
      "ua": {
        "properties": {
          "name": {
            "type": "keyword"
          },
          "device": {
            "type": "keyword"
          },
          "os": {
            "type": "keyword"
          }
        }
      },
      "tags": {
        "type": "keyword"
      }
    }
  }
}
```

### 5.2 ILM 정책 설정

```bash
# ILM 정책 생성
curl -X PUT "localhost:9200/_ilm/policy/tomcat-logs-policy" -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_age": "1d",
            "max_size": "50GB",
            "max_docs": 100000000
          },
          "set_priority": {
            "priority": 100
          }
        }
      },
      "warm": {
        "min_age": "3d",
        "actions": {
          "shrink": {
            "number_of_shards": 1
          },
          "forcemerge": {
            "max_num_segments": 1
          },
          "set_priority": {
            "priority": 50
          }
        }
      },
      "cold": {
        "min_age": "7d",
        "actions": {
          "set_priority": {
            "priority": 0
          },
          "freeze": {}
        }
      },
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}'

# 인덱스 템플릿에 ILM 정책 적용
curl -X PUT "localhost:9200/_index_template/tomcat-logs" -H 'Content-Type: application/json' -d'
{
  "index_patterns": ["tomcat-*"],
  "template": {
    "settings": {
      "index.lifecycle.name": "tomcat-logs-policy",
      "index.lifecycle.rollover_alias": "tomcat-logs"
    }
  }
}'
```

## 6. Kibana 대시보드 설정

### 6.1 Index Pattern 생성

```bash
# Kibana Dev Tools에서 실행
POST .kibana/_doc/index-pattern:tomcat-catalina
{
  "type": "index-pattern",
  "index-pattern": {
    "title": "tomcat-catalina-*",
    "timeFieldName": "@timestamp"
  }
}

POST .kibana/_doc/index-pattern:tomcat-stderr
{
  "type": "index-pattern",
  "index-pattern": {
    "title": "tomcat-stderr-*",
    "timeFieldName": "@timestamp"
  }
}

POST .kibana/_doc/index-pattern:tomcat-access
{
  "type": "index-pattern",
  "index-pattern": {
    "title": "tomcat-access-*",
    "timeFieldName": "@timestamp"
  }
}
```

### 6.2 검색 쿼리 예시

```json
# 에러 로그 검색
GET tomcat-stderr-*/_search
{
  "query": {
    "bool": {
      "must": [
        { "term": { "tags": "error" } },
        { "range": { "@timestamp": { "gte": "now-1h" } } }
      ]
    }
  },
  "sort": [
    { "@timestamp": "desc" }
  ]
}

# 느린 응답 검색 (Access 로그)
GET tomcat-access-*/_search
{
  "query": {
    "range": {
      "response_time": {
        "gte": 1000
      }
    }
  },
  "aggs": {
    "slow_requests": {
      "terms": {
        "field": "request_uri.keyword",
        "size": 10
      }
    }
  }
}

# 서버 에러 통계
GET tomcat-*/_search
{
  "query": {
    "term": {
      "response_status": "server_error"
    }
  },
  "aggs": {
    "errors_over_time": {
      "date_histogram": {
        "field": "@timestamp",
        "calendar_interval": "1h"
      }
    }
  }
}
```

## 7. 모니터링 및 운영

### 7.1 파이프라인 상태 확인

```powershell
# Windows (Filebeat 상태)
Get-Service filebeat
Get-Content C:\ProgramData\filebeat\logs\filebeat -Tail 20

# Filebeat 메트릭
Invoke-RestMethod -Uri "http://localhost:5066/stats" | ConvertTo-Json
```

```bash
# Linux (Kafka 상태)
# Consumer Lag 확인
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --group logstash-tomcat-catalina --describe

# 토픽별 메시지 수
for topic in tomcat-catalina tomcat-stderr tomcat-stdout tomcat-access; do
  echo "Topic: $topic"
  kafka-run-class.sh kafka.tools.GetOffsetShell \
    --broker-list localhost:9092 \
    --topic $topic \
    --time -1 | awk -F ':' '{sum += $3} END {print "Total messages:", sum}'
done

# Elasticsearch 인덱스 상태
curl -X GET "localhost:9200/_cat/indices/tomcat-*?v&h=index,docs.count,store.size"
```

### 7.2 자동화 스크립트

```powershell
# Monitor-TomcatLogs.ps1
# Tomcat 로그 파이프라인 모니터링

param(
    [switch]$Continuous
)

function Get-PipelineStatus {
    $status = @{}
    
    # Filebeat 상태
    $filebeat = Get-Service filebeat -ErrorAction SilentlyContinue
    $status.Filebeat = if ($filebeat) { $filebeat.Status } else { "Not Installed" }
    
    # Tomcat 로그 파일 확인
    $logPath = "C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs"
    $today = Get-Date -Format "yyyy-MM-dd"
    
    $status.LogFiles = @{
        Catalina = Test-Path "$logPath\catalina.$today.log"
        Stderr = Test-Path "$logPath\tomcat9-stderr.$today.log"
        Stdout = Test-Path "$logPath\tomcat9-stdout.$today.log"
        Access = Test-Path "$logPath\localhost_access_log.$today.txt"
    }
    
    # 최근 로그 크기
    $status.LogSizes = @{}
    Get-ChildItem $logPath -Filter "*$today*" | ForEach-Object {
        $status.LogSizes[$_.Name] = [math]::Round($_.Length / 1MB, 2)
    }
    
    # Filebeat 처리 상태
    try {
        $stats = Invoke-RestMethod -Uri "http://localhost:5066/stats" -TimeoutSec 2
        $status.FilebeatEvents = @{
            Active = $stats.filebeat.harvester.running
            Published = $stats.libbeat.output.events.acked
            Failed = $stats.libbeat.output.events.failed
        }
    } catch {
        $status.FilebeatEvents = "Monitoring unavailable"
    }
    
    return $status
}

# 실행
if ($Continuous) {
    while ($true) {
        Clear-Host
        Write-Host "=== Tomcat Log Pipeline Status ===" -ForegroundColor Cyan
        Write-Host "Time: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')" -ForegroundColor Yellow
        
        $status = Get-PipelineStatus
        $status | ConvertTo-Json -Depth 3
        
        Start-Sleep -Seconds 10
    }
} else {
    Get-PipelineStatus | ConvertTo-Json -Depth 3
}
```

## 8. 문제 해결 가이드

### 8.1 일반적인 문제와 해결

| 문제 | 원인 | 해결 방법 |
|------|------|----------|
| **로그가 Elasticsearch에 없음** | Filebeat 설정 오류 | `filebeat test config` 및 `filebeat test output` 실행 |
| **멀티라인 로그 깨짐** | 패턴 설정 오류 | multiline.pattern 검증, max_lines 증가 |
| **Kafka Lag 증가** | Logstash 처리 속도 부족 | consumer_threads 증가, 파티션 수 증가 |
| **인덱스 크기 과다** | 보존 정책 미설정 | ILM 정책 적용, 오래된 인덱스 삭제 |
| **스택트레이스 누락** | 멀티라인 제한 | multiline.max_lines 증가 (기본 500 → 2000) |

### 8.2 성능 최적화

```yaml
# Filebeat 최적화
filebeat.inputs:
- type: log
  # 버퍼 크기 증가
  harvester_buffer_size: 32768
  # 배치 크기
  max_bytes: 20971520  # 20MB
  # 백프레셔 처리
  backoff: 1s
  max_backoff: 10s

# Logstash 최적화
pipeline.workers: 8
pipeline.batch.size: 250
pipeline.batch.delay: 5

# Elasticsearch 최적화
index.refresh_interval: 30s  # 실시간성이 중요하지 않은 경우
index.translog.durability: async
```

## 9. 보안 설정

### 9.1 Kafka 인증 (선택사항)

```yaml
# Filebeat Kafka 출력 보안
output.kafka:
  hosts: ["kafka1:9093", "kafka2:9093"]
  topic: 'tomcat-%{[fields.log_type]}'
  
  # SSL/TLS
  ssl.enabled: true
  ssl.certificate_authorities: ["C:\\Certs\\ca-cert.pem"]
  
  # SASL 인증
  sasl.mechanism: SCRAM-SHA-512
  username: "filebeat-user"
  password: "${KAFKA_PASSWORD}"
```

### 9.2 민감 정보 마스킹

```ruby
# Logstash 필터에 추가
filter {
  # 민감 정보 마스킹
  mutate {
    gsub => [
      "message", "password=\S+", "password=***MASKED***",
      "message", "token=\S+", "token=***MASKED***",
      "message", "\b\d{3}-\d{2}-\d{4}\b", "***-**-****"  # SSN
    ]
  }
}
```

## 10. 전체 구조 요약

### 10.1 데이터 흐름

```
1. Tomcat 로그 파일 생성 (7종류)
   ↓
2. Filebeat 수집 (log_type 태깅)
   ↓
3. Kafka 토픽 (로그 타입별 분리)
   ↓
4. Logstash 처리 (파싱, 변환, 강화)
   ↓
5. Elasticsearch 인덱싱 (일별 인덱스)
   ↓
6. Kibana 시각화
```

### 10.2 인덱스 구조

```
tomcat-catalina-2024.12.08   → 서버 메인 로그
tomcat-stderr-2024.12.08     → 에러 출력 (예외, 스택트레이스)
tomcat-stdout-2024.12.08     → 표준 출력 (애플리케이션 로그)
tomcat-access-2024.12.08     → HTTP 접근 로그
tomcat-localhost-2024.12.08  → 로컬호스트 로그
tomcat-manager-2024.12.08    → 매니저 앱 로그
tomcat-host-manager-2024.12.08 → 호스트 매니저 로그
```

### 10.3 핵심 설정 체크리스트

- [x] Filebeat: 각 로그 파일별 input 설정
- [x] Filebeat: 멀티라인 패턴 설정 (스택트레이스)
- [x] Filebeat: JavaScript 프로세서 제거 (호환성 문제 방지)
- [x] Kafka: 로그 타입별 토픽 생성
- [x] Logstash: 로그 타입별 파싱 로직
- [x] Elasticsearch: 인덱스 템플릿 및 ILM 정책
- [x] Kibana: Index Pattern 생성
- [x] 모니터링: Consumer Lag, 인덱스 크기 확인

## 11. 주의사항 및 트러블슈팅

### 11.1 JavaScript 프로세서 에러 해결

Windows Filebeat에서 JavaScript 프로세서 사용 시 다음과 같은 에러가 발생할 수 있습니다:
```
Exiting: error initializing processors: the processor action does not exist. Valid actions: script
```

**해결 방법**: JavaScript 프로세서를 제거하고 조건부 `add_fields` 프로세서로 대체했습니다.

### 11.2 설정 검증 명령어

```powershell
# 설정 파일 문법 검사 (반드시 실행)
cd "C:\Program Files\Filebeat"
.\filebeat.exe test config -c filebeat.yml

# 출력 연결 테스트
.\filebeat.exe test output -c filebeat.yml

# 문제 발생 시 디버그 모드 실행
.\filebeat.exe -e -c filebeat.yml -d "*"
```

### 11.3 최소 설정으로 시작

문제가 지속되면 최소 설정으로 시작하여 단계적으로 추가:

```yaml
# filebeat-minimal.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - 'C:\Program Files\Apache Software Foundation\Tomcat 9.0\logs\catalina.*.log'
  fields:
    log_type: catalina
  # 멀티라인 설정 (multiline.type 제거)
  multiline.pattern: '^\d{2}-[A-Za-z]{3}-\d{4}'
  multiline.negate: true
  multiline.match: after

output.kafka:
  hosts: ["192.168.1.101:9092"]
  topic: 'tomcat-catalina'

logging.level: info
```

이 구조로 Tomcat의 모든 로그를 체계적으로 수집, 처리, 저장할 수 있습니다.
